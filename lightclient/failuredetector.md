***This is the beginning of an unfinished draft. Don't continue reading!***

# Failure detector

A failure detector is a process that gets as input a header with some height *h*, connects to different Tendermint full nodes, requests the header of height *h* from them, and then cross-checks the headers and the input header.

There are two foreseeable use cases:

1) strengthen the lite client: If a lite client accepts a header *hd* (after performing skipping or sequential verification), it can use the failure detector to probe the system for conflicting header and increase the trust in *hd*. Instead of communicating with a single full node, communicating with several full nodes shall increase the probability to be aware of a fork in case there is one.

2) to support fork accountability: In the case when more than 1/3 of the voting power is held by faulty validators, faulty nodes may generate two conflicting headers for the same height. The goal of the failure detector is to learn about the conflicting headers by probing different full nodes. Once a failure detector has two conflicting headers, these headers are evidence of misbehavior. A natural extension is to use the failure detector within a monitor process (on a full node) that calls the failure detector on a sample (or all) headers (in parallel). (If the sample is chosen at random, this adds a level of probabilistic reasoning.) If conflicting headers are found, they are evidence that can be used for punishing processes.

In this document we will focus in strengthening the lite client, and leave other uses of the failure detection mechanism (e.g., when run on a full node) to the future.

This document refers to the lite client ADR [77d2651 on Dec 27, 2019]
https://github.com/interchainio/tendermint-rs/blob/e2cb9aca0b95430fca2eac154edddc9588038982/docs/architecture/adr-002-lite-client.md

## Context of this document

The lite client verification specification [026fdde on Jan 23, 2019]
https://github.com/tendermint/spec/blob/master/spec/consensus/light-client/verification.md
is designed for the Tendermint failure model (1/3 assumption). It is safe under this assumption, and live if it can reliably and timely communicate with a correct full node. If this assumption is violated, the lite client can be fooled to trust a header that was not generated by Tendermint consensus.

This specification, the failure detector, is a "second line of defense", in case the 1/3 assumption is violated. Its goal is to collect evidence. However, it is impractical to probe all full nodes. At this time we consider a simple scheme of maintaining an address book of known full nodes from which a small subset (4) are chosen initially to communicate with. More involved book keeping with probabilistic guarantees (such as PEX or Brahms) can be considered at later stages of the project.



The lite client maintains a simple address book (according to the ADR):
- Fixed list of full nodes provided in the configuration upon initialization
- Select one full as primary, select 3 as secondary. These nodes
  constitute the initial peer set.
- The bisector communicates with the primary
- The bisector gets headers from the primary, and stores them in *State*

### Informal Problem statement

> I put tags to informal problem statements as there is no sequential secification.

#### **[LCD-IP-Q]** 

Whenever the light client verifier adds a new pair
_(p,h)_ containing the primary _p_ and a header _h_ to *State*, the
failure detector should query the secondaries by calling `Commit` remotely. 

#### **[LCD-IP-RespOK]** 

If a header *h'* returned by the secondary *s* is
equal to *h* we add _(s,h)_ to state.

_Remark:_ We use the procedure `Add_to_state(s,h)`.
This information might later be useful in case we find a
problem when we get another header for this height from a different secondary.




#### **[LCD-IP-RespBad]** 

Otherwise, that is if *h'* returned by _s_ is
different from *h*, we analyze the situation. If the failure detector
can prove a fork on the main chain by bisecting with _s_, it panics: stops the
light client and submits evidence. 


#### **[LCD-IP-PEERSET]** 

Whenever the failure detector observes misbehavior of a full node from
the peer set it should be replaced by a fresh full node. (A full node
that has not been in the peer set before)






## Assumptions/Incentives/Environment

It is not in the interest of faulty full nodes to talk to the failure detector as long as the failure detector is connected to at least one correct full node. This would only increase the likelihood of misbehavior being detected. Also we cannot punish them easily (cheaply). The absence of a response need not be the fault of the full node. Also, a faulty failure detector could wrongly accuse correct full nodes.

Correct full nodes have the incentive to respond, because the failure detector may help them to understand whether their header is a good one. We can thus base liveness arguments of the failure detector on the assumptions that correct full nodes reliably talk to us.


**Assumptions**

**[LCD-A-CorrFull]** At all times there is at least one correct full node among the primary and the secondary.

**[LCD-A-RelComm]** Communication between the failure detector and a correct full node is reliable and bounded in time.

**Q6: Are we limiting ourselves to the scenario 1/3 n <= f <= 2/3 n**



## Problem statement

**[LCD-VC-INV]** If there is no fork at height *h*, and the primary and the secondaries are correct, then the failure detector should never output evidence for height *h*.

**[LCD-VC-LIFE-FORK]** If there is a fork (two correct full nodes decided on different blocks for the same height), and
- the user of the lite client requests a header of a height *h* that is affected (within the trusting period), and
- there are two correct full nodes *i* and *j* that are
    - on different branches, and
    - primary or secondary,

then the failure detector eventually outputs evidence for height *h*.

**[LCD-VC-LIFE-FLTPRIM]** If the bisection trusts a header at height *h* that deviates from the header on the chain (possibly because the primary is faulty), and there is a correct secondary,
then the failure detector eventually outputs evidence for height *h*.

**[LCD-VC-LIFE-CONFL]**  If the failure detector observes two conflicting headers for height *h*, it reports evidence for height *h*.

*Remark:* Liveness 3 is more operational and talks about operational details of the failure detector. Perhaps it should better be addressed by something like to following requirement:

**[LCD-REQ-REP]** If the failure detector observes two conflicting headers for height *h*, it should try to verify both. If both are verified it should report evidence.


## Definitions


## Solution



### Inter Process Communication



For the purpose of this light client specification, we assume that the
     Tendermint Full Node exposes the following functions over
     Tendermint RPC:

```go
func Commit(addr Address, height int64) (SignedHeader, error)
```
- Implementation remark
   - RPC to full node _n_ at address _addr_
- Expected precodnition
  - header of `height` exists on blockchain
- Expected postcondition
  - if _n_ is correct: Returns a sound signed header of height `height`
  from the blockchain if communication is timely (no timeout)
  - if _n_ is faulty: Returns a signed header with arbitrary content
- Error condition
   * if _n_ is correct: precondition violated or timeout
   * if _n_ is faulty: arbitrary error

----

### Auxiliary Functions (Local)

```go
Replace_peer(addr Address)
```
... by a fresh full node


```go
Report_and_Stop(sh)
```

From the verifier

```go
VerifyHeaderAtHeight
```

## Solution

Shared data of the light client
- peer set
- primary



We start with the function `FailureDetector` with a header that has
just been verified by the verifier. _trustedState_ should be the
trusted state on which the verifier has based the addition

```go
func FailureDetector(hd Header,trustedState TrustedState) (evidence)
  for each s in Secondaries {
    sh := Commit(s,hd.height)
	if validateSignedHeaderAndVals(sh,...) fails
	    // sh is malformed (fails basic validation): *s* is
        // faulty. We replace it in the peer set by a different full node
	   Replace_peer(s)
    else {
	  // we try to verify sh by querying s
	  result := VerifyHeaderAtHeight(sh.height, trusted state, s)
	  if result = (sh,OK) {
	    // there is a fork on the main blockchain. -> call panic
	    // with all the evidence
	      Report_and_Stop(sh)
	  } else if  result = (sh,EXPIRED) {
	    // there is a fork on the main
	    // blockchain but trusting period expired. -> if still
	    // within unbonding period call panic
	     if within_unbonding(sh) {
		   Report_and_Stop(sh)
		 }
		 else {
		   // try with later trusted state?
		   TODO
		 }
	  } else {
	   //  _s_ might be faulty or unreachable
	   Replace_peer(s)
	  }
	}
  }


```


There are several cases to distinguish

   - **C1.** *h'* is malformed (fails basic validation): *s* is
     faulty. We replace it in the peer set by a different full node by
     calling `Replace_peer(s)`
     (that has not been in the peer set before)
   - **C2.** otherwise, the failure detector tries to verify *h'* by
     doing bisection with secondary _s_ (``-- or
     an optimized version that does not download _h'_ again). We
     distinguish the cases according to the return value of
     `VerifyHeaderAtHeight`:
	 
        - **C2OK.** (h', OK): *h'* can be verified: 
		      there is a fork on the main blockchain. -> call panic
		      with all the evidence
		- **C2EXP.** (h', EXPIRED) there is a fork on the main
		      blockchain but trusting period expired. -> if still
		      within unbonding period call panic
		      with all the evidence. TODO: Otherwise?
        - **C2L.** fails -> _s_ might be faulty or unreachable -> `Replace_peer(s)`

