***This is the beginning of an unfinished draft. Don't continue reading!***

# Failure detector

A failure detector is a process that gets as input a header with some height *h*, connects to different Tendermint full nodes, requests the header of height *h* from them, and then cross-checks the headers and the input header.

There are two forseeable use cases:

1) strengthen the lite client: If a lite client accepts a header *hd* (after performing skipping or sequential verification), it can use the failure detector to probe the system for conflicting header and increase the trust in *hd*. Instead of communicating with a single full node, communicating with several full nodes shall increase the probability to be aware of a fork in case there is one.

2) to support fork accountability: In the case when more than 1/3 of the voting power is held by faulty validators, faulty nodes may generate two conflicting headers for the same height. The goal of the failure detector is to learn about the conflicting headers by probing different full nodes. Once a failure detector has two conflicting headers, these headers are evidence of misbehavior. A natural extension is to use the failure detector within a monitor process (on a full node) that calls the failure detector on a sample (or all) headers (in parallel). (If the sample is chosen at random, this adds a level of probabilistic reasoning.) If conflicting headers are found, they are evidence that can be used for punishing processes.

In this document we will focus in strengthening the lite client, and leave other uses of the failure detection mechanism (e.g., when run on a full node) to the future.

This document refers to the lite client ADR [77d2651 on Dec 27, 2019]
https://github.com/interchainio/tendermint-rs/blob/e2cb9aca0b95430fca2eac154edddc9588038982/docs/architecture/adr-002-lite-client.md

## Context of this document

The lite client verification specification [026fdde on Jan 23, 2019]
https://github.com/tendermint/spec/blob/master/spec/consensus/light-client/verification.md
is designed for the Tendermint failure model (1/3 assumption). It is safe under this assumption, and live if it can reliably and timely communicate with a correct full node. If this assumption is violated, the lite client can be fooled to trust a header that was not generated by Tendermint consensus.

This specification, the failure detector, is a "second line of defense", in case the 1/3 assumption is violated. Its goal is to collect evidence. However, it is impractical to probe all full nodes. At this time we consider a simple scheme of maintaining an address book of known full nodes from which a small subset (4) are chosen initially to communicate with. More involved book keeping with probabilistic guarantees (such as PEX or Brahms) can be considered at later stages of the project.



The lite client maintains a simple address book (according to the ADR):
- Fixed list of full nodes provided in the configuration upon initialization
- Select one full as primary, select 3 as secondary
- The bisector communicates with the primary
- The bisector gets headers from the primary, and stores them in *State*

### Informal Problem statement

Whenever a new header *h* is added to *State*, the failure detector should query the secondaries.

If a header *h'* returned by the secondary *s* is equal to *h* we do nothing. **(Q1: or should we record it, as this information might later be useful in case we find a problem when we get another header for this height from a different secondary??)** Otherwise, that is if *h'* is
different from *h*, we have a fork. There are several cases to distinguish

   - **C1.** *h'* is malformed (fails basic validation): *s* is faulty
   - **C2.** otherwise, the failure detector tries to verify *h'* by bisection

        - **C2F.** *h'* can be verified: there is a fork on the main blockchain
        - **C2L.** otherwise: ?

**Q2: Which cases should we distinguish in C2L? e.g.:
(1) timeout, (2) trusting period expired (do we consider it a fork if the signatures are fine, but the trusting period expired?), (3) lunatic attack.**  

**Q3: Is C1 the only case where we can mark a secondary faulty?**

**Q4: Should the failure detector analyze the headers, e.g., look for double signing? Or should it just report both headers.**



**Q5: If there is a fork, what should the lite client as a whole do? Just issue a warning to the user?**

We have the following additional requirements

- Any peers that errored should be marked bad

- Update primary and secondaries as necessary (i.e. when any are marked bad)

- If there's a verified conflict, persist it, log the error, attempt to broadcast (if Tendermint supports it ...)

**Q7: should this be part of this specification or should this be treated somewhere else?**

### Evidence processing

How the generated evidence is used, will be discussed in another document. One solution would be that the failure detector tries to get the evidence accepted on the main chain, which may work in practical scenarios, e.g., if there was no attack on the main chain (agreement of the validators is never violated), but there was an attack on a light client.

 In theory, however,
given that the 1/3 assumption is necessarily violated to violate agreement, there are possible complications to submitting the evidence to the chain:

- evidence might be censored (faulty validators have enough votes to prevent deciding on a block that contains the evidence)
- the faulty processes block all progress. The chain comes to a halt.
- the faulty processes actually generated a fork and both branches make progress (with different correct processes participating in different branches). In this case, none of the branches is "more correct" than the other one. We necessarily fall back to social consensus.

Due to these complications, in the worst case we may need to fall back to social consensus. Also for this, the evidence of the fault detector will be crucial to figure out who misbehaved/what went wrong. In this sense, this specification can be studied independently of the actual fork accountability and punishment scheme.


## Assumptions/Incentives/Environment

It is not in the interest of faulty full nodes to talk to the failure detector as long as the failure detector is connected to at least one correct full node. This would only increase the likelihood of misbehavior being detected. Also we cannot punish them easily (cheaply). The absence of a response need not be the fault of the full node. Also, a faulty failure detector could wrongly accuse correct full nodes.

Correct full nodes have the incentive to respond, because the failure detector may help them to understand whether their header is a good one. We can thus base liveness arguments of the failure detector on the assumptions that correct full nodes reliably talk to us.


**Assumptions**

- **A1.** At all times there is at least one correct full node among the primary and the secondary.

- **A2.** Communication between the failure detector and a correct full node is reliable and bounded in time.

**Q6: Are we limiting ourselves to the scenario 1/3 n <= f <= 2/3 n**



## Problem statement

**Safety 1.** If there is no fork at height *h*, and the primary and the secondaries are correct, then the failure detector should never output evidence for height *h*.

**Liveness 1.** If there is a fork (two correct full nodes decided on different blocks for the same height), and
- the user of the lite client requests a header of a height *h* that is affected (within the trusting period), and
- there are two correct full nodes *i* and *j* that are
    - on different branches, and
    - primary or secondary,

then the failure detector eventually outputs evidence for height *h*.

**Liveness 2.** If the bisection trusts a header at height *h* that deviates from the header on the chain (possibly because the primary is faulty), and there is a correct secondary,
then the failure detector eventually outputs evidence for height *h*.

**Liveness 3.** If the failure detector observes two conflicting headers for height *h*, it reports evidence for height *h*.

**Remark.** Liveness 3 is more operational and talks about operational details of the failure detector. Perhaps it should better be addressed by something like to following requirement:

**Requirement 1.** If the failure detector observes two conflicting headers for height *h*, it should try to verify both. If both are verified it should report evidence.
