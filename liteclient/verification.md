*** This is the beginning of an unfinished draft. Don't continue reading! ***

# Core Verification

<< Rough outline of what the component is doing and why. 2-3 paragraphs >>

The lite client implements a read operation of a block (header) from the
blockchain. It does so by communicating with full nodes. As full nodes
may be faulty, this functionality must be implemented in a fault-tolerant
way.



# Part I - Outside view

## Context of this document

<< mention other components and or specifications that are relevant for this
spec. Possible interactions, possible use cases, etc. >>

In this specification we specify the communication of the lite client with
full nodes. As full nodes may be faulty, the lite client has to check whether
the header it receives are the ones generated by Tendermint consensus. The
central features used in this specification are:

 - Tendermint blocks
(and headers) extensively use digital signatures and hashes to prove that a
block is OK.

 - the Tendermint failure model that guarantees that there is a set of full nodes
 that represent more than 2/3 of the
 voting power in the "next validators" set
 are correct from the time a block is generated until the trusting period is
 passed.

<< should give the reader the understanding in what environment this component
will be used. >>

## Informal Problem statement

Given a height *h* as an input, the lite client outputs the header of
height *h* that is generated by Tendermint consensus.


## Sequential Problem statement

The blockchain is a list of headers with strictly increasing heights.

If the blockchain contains a header of height *h*, then for all $h'<h$
it contains a header.

During operation, new headers may be appended to the list.

The lite client gets as input an integer, and eventually outputs the header
of height *h*.

# Part II - Protocol view

## Environment/Assumptions/Incentives


<< Introduce distributed aspects >>

<< Timing and correctness assumptions. Possibly with justification that the
assumptions make sense, e.g., it is in the interest of a full node to behave
correctly >>

Lite client verification communicates with a full node of a Tendermint block chain.

### Incentives

Faulty full nodes may benefit from lying to the lite client, e.g., if
the lite client accepts a block that deviates (e.g., contains
  additional transactions) from the one generated
by Tendermint consensus. Users using the lite client might be harmed
by accepting a forged header.

In combination with the lite client failure detector,
correct full nodes have the incentive to respond, because the failure detector of the lite client may help them to understand whether their header is a good one. We can thus base liveness arguments on the assumptions that correct full nodes reliably talk to us.



### Tendermint Failure Model

If a block _h_ is generated at time _bfttime_ (and this time is stored in the block), then a set of validators that hold more than 2/3 of the voting power in h.Header.NextV is correct until time h.Header.bfttime + tp.

Formally,
\[
\sum*{(v,p) \in h.Header.NextV \wedge correct(v,h.Header.bfttime + tp)} p >
2/3 \sum*{(v,p) \in h.Header.NextV} p
\]

_Assumption_: "correct" is defined w.r.t. realtime (some Newtonian global notion of time, i.e., wall time), while _bfttime_ corresponds to the reading of the local clock of a validator (how this time is computed may change when the Tendermint consensus is modified). In this note, we assume that all clocks are synchronized to realtime. We can make this more precise eventually (incorporating clock drift, accuracy, precision, etc.). Right now, we consider this assumption sufficient, as clock synchronization (under NTP) is in the order of milliseconds and _tp_ is in the order of weeks.


**Assumptions**

- **A1.**  Communication between the lite client and a correct full node is reliable and bounded in time.




## Problem Statement

<< safety specifications / invariants in English >>


<< liveness specifications in English. Possibly with timing/fairness requirements:
e.g., if the component is connected to a correct full node and communication is
reliable and timely, then something good happens eventually. >>

<< should have clear formalization in temporal logic. >>


The lite client has a local data structure called TrustedState that contains headers.

Trusted State is initialized with _inithead_ that was correctly generated by the Tendermint consensus.

- Lite Client Invariant: Every header _h_ in _TrustedState_   was generated by an instance of Tendermint consensus.


From time to time, lite client verification is called with a header _h_. Each instance must satisfy the following properties

- Verification Liveness: If header _h_ was correctly generated by an instance of Tendermint consensus (and its age is less than the trusting period), then the lite client should eventually _h_ to trusted state.

_Remark_: The case where _h_ was not correctly generated is covered
by the Lite Client Invariant.

_Remark_: The Lite Client Invariant and Verification Liveness
allow that headers are added to _TrustedState_ that where not passed
to verification.

_Remark_: In Liveness we use "eventually", while in practice _trust(h)_ should be set to true before _h.Header.bfttime + tp_. If not, the block cannot be trusted because it is too old.



## Definitions

In this section we become more concrete, with basic data types,

some math that allows to write specifications and pseudo code solution below.
Some variables, etc.

## Solution

<< Basic data structures. Simplified, so that we can focus on the distributed
algorithm here. If existing: link to Tendermint data structures, and mentioned
if details were omitted. >>

<< Pseudo code of the solution >>


## Correctness arguments

<< Proof sketches of why we believe the solution satisfies the specifications.
Possibly giving inductive invariants that can be used to prove the specifications >>
<<Link to Part I>>
